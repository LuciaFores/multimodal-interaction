{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the needed libraries\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import pyaudio\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from pygame import mixer\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be used to setup the speech recognition module\n",
    "def setup_speech_recognition():\n",
    "    # Load the model and create a recognizer\n",
    "    model = Model(\"./model/vosk-model-small-it-0.22\")\n",
    "    recognizer = KaldiRecognizer(model, 16000)\n",
    "    # setup the microphone to record audio\n",
    "    mic = pyaudio.PyAudio()\n",
    "    stream = mic.open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=16000,\n",
    "        input=True,\n",
    "        frames_per_buffer=8192\n",
    "    )\n",
    "    stream.stop_stream()  # Start with the stream stopped\n",
    "    # return the recognizer and the stream\n",
    "    return recognizer, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be used to setup the speech synthesis module\n",
    "def setup_speech_synthesis():\n",
    "    # setup the mixer to play the audio\n",
    "    mixer.init()\n",
    "    # return the mixer\n",
    "    return mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be used to recognize the speech\n",
    "def recognize_speech(recognizer, stream):\n",
    "    # read the audio data from the stream\n",
    "    data = stream.read(4096)\n",
    "    # check if the data is empty\n",
    "    if len(data) == 0:\n",
    "        return None\n",
    "    # check if the recognizer has recognized the speech\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        # return the recognized speech\n",
    "        return recognizer.Result()[14:-3] # remove the first 14 characters and the last 3 characters, needed to remove the metadata\n",
    "    # return None if the speech is not recognized\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be used to synthesize the speech\n",
    "def synthesize_speech(text):\n",
    "    # create a BytesIO object to store the mp3 file\n",
    "    mp3_fp = BytesIO()\n",
    "    # create a gTTS object and write the mp3 file to the BytesIO object and so perform the synthesis\n",
    "    tts = gTTS(text, lang='it')\n",
    "    tts.write_to_fp(mp3_fp)\n",
    "    return mp3_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be used to play the synthesized speech\n",
    "def play_speech(mixer, mp3_fp):\n",
    "    # set the BytesIO object to the beginning of the file\n",
    "    mp3_fp.seek(0)\n",
    "    # play the mp3 file\n",
    "    mixer.music.load(mp3_fp)\n",
    "    mixer.music.play()\n",
    "    # wait until the audio is played\n",
    "    while mixer.music.get_busy():\n",
    "        time.sleep(0.1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to retrieve patient data\n",
    "def get_patient_data():\n",
    "    df_registry = pd.read_csv('./patient_registry_test.csv')\n",
    "    # create a dictionary with the patient data\n",
    "    patient = {}\n",
    "    patient['name'] = df_registry['name'][0]\n",
    "    patient['gender'] = df_registry['gender'][0]\n",
    "    patient['age'] = int(df_registry['age'][0])\n",
    "    df_therapy_plan = pd.read_csv('./therapy_plan_test.csv')\n",
    "    # create a dictionary with the therapy plan data\n",
    "    therapy_plan = {}\n",
    "    # iterate over the therapy plan data and get only the rows for which the column medicine_1 is not empty\n",
    "    for _, row in df_therapy_plan.iterrows():\n",
    "        if not pd.isna(row['medicine_1']): # meaning that the patient must take at least one medicine at that time\n",
    "            # get all the medicines that the patient must take at that time\n",
    "            medicines = row.drop(['hour']).dropna().tolist()\n",
    "            therapy_plan[row['hour']] = medicines\n",
    "    return patient, therapy_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to greet the patient\n",
    "def greet_patient(patient):\n",
    "    # create the text to be synthesized\n",
    "    text = f'Ciao {patient[\"name\"]}, benvenuto alla terapia vocale. Come stai oggi?'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_interaction(stream, text, mixer, recognizer):\n",
    "    mp3_fp = synthesize_speech(text)\n",
    "    play_speech(mixer, mp3_fp)\n",
    "    stream.start_stream()\n",
    "    patient_speech = None\n",
    "    while patient_speech == None:\n",
    "        patient_speech = recognize_speech(recognizer, stream)\n",
    "    stream.stop_stream()\n",
    "    time.sleep(1)\n",
    "    return patient_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient, therapy_plan = get_patient_data()\n",
    "recognizer, stream = setup_speech_recognition()\n",
    "mixer = setup_speech_synthesis()\n",
    "patient_speech = None\n",
    "while patient_speech != \"buonanotte\":\n",
    "    text = \"\"\n",
    "    if patient_speech == None:\n",
    "        text = greet_patient(patient)\n",
    "        stream.stop_stream()\n",
    "        patient_speech = speech_interaction(stream, text, mixer, recognizer)\n",
    "    elif patient_speech.startswith(\"ben\"):\n",
    "        text = \"Sono contento di sentirtelo dire \" + patient[\"name\"] + \".\"\n",
    "        text += \"Oggi dovrai prendere i seguenti farmaci: \"\n",
    "        text += \", \".join([','.join(lst) for lst in therapy_plan.values()])\n",
    "        stream.stop_stream()\n",
    "        patient_speech = speech_interaction(stream, text, mixer, recognizer)\n",
    "    elif patient_speech.startswith(\"mal\"):\n",
    "        text = \"Mi dispiace, spero che ti senta meglio presto\"\n",
    "    else:\n",
    "        text = \"Non ho capito cosa hai detto\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_interaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
